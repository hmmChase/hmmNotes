# _GraphQL Backend_

---

- The main components:
  - `.graphqlconfig.yml`
    - ?
  - `database`: This directory holds all the files that relate to your Prisma database service
    - `prisma.yml`
      - The main configuration file for your Prisma setup
      - https://www.prisma.io/docs/prisma-cli-and-configuration/prisma-yml-5cy7/
    - `datamodel.graphql`
      - Specifies the datamodel for your application that will be mapped to the database
        - It basically defines your database schema
      - Uses GraphQL Schema Definition Language (SDL)
  - `src`: This directory holds the source files for your GraphQL server
    - `schema.graphql`
      - Contains your application schema
      - Contains the GraphQL schema which defines all the operations (queries, mutations and subscriptions) you can send from your frontend app
      - Only this file is relevant to a frontend developer
    - `generated/`
      - `prisma.graphql`
        - Contains the auto-generated Prisma database schema
        - The Prisma schema defines powerful CRUD operations for the types in your data model
        - Never edit this file manually since it gets automatically updated when the data model changes
      - `index.js`
        - ?
      - `prisma-client`
        - ?
      - `index.d.ts`
        - Allows auto-completion in your IDE when reading and writing data using the Prisma client
    - `resolvers`
      - Contains the resolver functions for the operations defined in the application schema
    - `index.js`
      - The entry point for your GraphQL server

---

# _Prisma_

- https://github.com/prisma/prisma
- https://github.com/prisma/prisma-examples
- https://www.prisma.io/tutorials
- Adds a database layer to a GraphQL server
- Prisma enables seamless type-safe database access & declarative data modeling
- Bridges the gap between your database and GraphQL resolvers
- Replaces traditional ORMs
- Gives a set of GraphQL CRUD APIs for MySQL, Postgres, MongoDB databases
- Define a data model and auto-generate CRUD APIs based on it
- Will create tables in your database on your behalf
- Schema definition
- Data relationships
- Can be queried directly from Yoga server
- Self-hosted or SaaS

## Setup

- For the first time, globally install the Prisma CLI and login:
  - `npm i -g prisma`
  - `prisma login`
- cd to backend
- `prisma init`
- Create a `.env` file and add to `.gitignore`

```
FRONTEND_URL="http://localhost:7777"
PRISMA_ENDPOINT="yougottafillthisout"
PRISMA_SECRET="typeasecretstringhere"
APP_SECRET="jwtsecret123"
STRIPE_SECRET="sk_123youchanget his"
PORT=4444
```

    * Replace `PRISMA_ENDPOINT` value with endpoint from `prisma.yml`

- Update `prisma.yml`

```
endpoint: ${env:PRISMA_ENDPOINT}
datamodel: datamodel.prisma
# secret: ${env:PRISMA_SECRET}
hooks:
  post-deploy:
    - graphql get-schema -p prisma
```

    * ``endpoint``: The HTTP endpoint for your Prisma API
    * ``datamodel``: Points to the datamodel file
    * `hooks`
        * https://www.prisma.io/docs/prisma-cli-and-configuration/prisma-yml-5cy7/#hooks-optional

- Define the data model in `datamodel.prisma`

```
type Item {
  id: ID! @unique
  title: String!
  description: String!
}
```

- Uncomment `secret` before deploying or the database will be accessible by anyone
- `prisma deploy`
  - demo database creates a free [AWS Aurora](https://aws.amazon.com/de/rds/aurora/) that’s hosted in Prisma Cloud

## Import

- `import` doesn't exist in GraphQL, but Prisma makes it available by using `#`
- `# import * from './generated/prisma.graphql'`

## Playground

- A “GraphQL IDE”, providing an interactive environment that allows to send queries, mutations and subscriptions to your GraphQL API
- It is similar to a tool like Postman
- Has built-in documentation for its GraphQL API
- Log into prisma.io and select the service
- Press `ctrl + space` to bring up the tooltip
- Allows you to interact with two GraphQL APIs
  - Application schema
    - This is the one your React application will interact with
    - It can be opened by selecting the default Playground in the app project in the left side-menu
  - Prisma database API
    - Provides full access to the data stored in the database
    - This one you can open by selecting the dev Playground in the database project in the left side-menu
    - This API is defined by the Prisma schema (in `server/src/generated/prisma.graphql`).

## Data Model

- https://www.prisma.io/blog/datamodel-v11-lrzqy1f56c90
- The data model is the foundation for the GraphQL API generated by Prisma
- Provides powerful CRUD operations for the types in the data model
- Tells Prisma how to configure you database
- Each model will be mapped to a table in the underlying database
- Prisma automatically creates `updatedAt` and `createdAt` fields
  - read-only
- ``id``:`ID`!``` @id` is a special field in the Prisma datamodel
  - Prisma will auto-generate globally unique IDs for the types that have this field
- The `@unique` directive tells Prisma that you never want any two elements in the database that have the same value for that field

## Directives

- https://www.prisma.io/docs/1.32/datamodel-and-migrations/datamodel-MYSQL-knul/#sdl-directives

## APIs

- Prisma provides two APIs
- The application schema, also called application layer
  - Only an interface to the database
  - It defines the operations your client applications will be able to send to your API
    - This includes business logic as well as other common features and workflows
      - such as signup and login
- The database layer defined by the Prisma schema
  - It provides powerful CRUD operations that allow you to perform any kind of operation against the data in your database

## Prisma Client & Server

- The Prisma server provides the data access layer in your application architecture, making it easy for your API server to talk to the database through Prisma
- The API of the Prisma server is consumed by the Prisma client inside your API server implementation
  - Similar to an ORM
  - The API server can be implemented with `apollo-server` or `graphql-yoga`, among others
- When using Prisma Client, you’re implementing your resolvers such that they’re simply forwarding incoming queries to the underlying Prisma engine, which in turn resolves the query against the actual database
- The Prisma client is an auto-generated client library that lets you read and write data in your database through the Prisma API
- You can generate it using the `prisma generate` command
  - Reads the information from `prisma.yml` and generates the Prisma client accordingly

## Connecting Server and Database with the Prisma Client

- Connect your GraphQL server with the Prisma API
- The connection is implemented via the Prisma client
- Attach the `prisma` client instance to the `context`
  - Lets you access your database through the Prisma API
  - Exposes a number of methods that let you perform CRUD operations for your models
  - Update `index.js`

```
const server = new GraphQLServer({
  typeDefs: './src/schema.graphql',
  resolvers,
  context: { prisma },
})
```

- Implementing in resolvers:

```
feed: (root, args, context, info) => {
  return context.prisma.links()
},
```

    * It accesses a ``prisma`` object on ``context``
    * You’re invoking a function on the ``prisma`` client instance

## Info

- https://www.prisma.io/blog/graphql-server-basics-demystifying-the-info-argument-in-graphql-resolvers-6f26249f613a

## Relations

- https://www.prisma.io/docs/prisma-client/basic-data-access/reading-data-JAVASCRIPT-rsc2/#relations
- Defines the semantics of a connection between two types
- Prisma client has a fluent API to query relations in your database
  - Meaning you can simply chain your method calls to navigate the relation properties of the returned records
  - This is only possible when retrieving single records, not for lists
  - `context.prisma.link({ id: parent.id }).postedBy();`

## Introspection

- This introspects your database and generates a datamodel
- Can be used to generate a datamodel written in the new syntax
- Run the following command inside the directory where your `prisma.yml` is located:
  - `prisma introspect`

## Tutorials

- https://www.prisma.io/tutorials/

---

# _Nexus_

- https://nexus.js.org/
- https://github.com/prisma/nexus
- Code-First, Type-Safe, GraphQL Schema Construction

---

# _GraphQL Yoga_

- https://github.com/prisma/graphql-yoga/
- Fully-featured GraphQL Server with focus on easy setup, performance & great developer experience
- Built on Express and Apollo Server
- A logic layer before data is put in the database
- Creates the GraphQL endpoint
- Sends data to Prisma to be stored in database
- Sits between the client and database
- Implement Query and Mutation Resolvers
- Allows custom server-side logic:
  - Charging Credit Cards
  - Sending emails
  - Performing JWT Authentication
  - Checking Permissions

## Setup

- `npm i graphql-yoga`
- `npm i prisma-binding`
  - JavaScript bindings for Prisma to interact with GraphQL database
  - Gives the ability to query the Prisma database
- Create a `/src/db.js` file
  - Connects to the remote Prisma DB and gives us the ability to query it with JavaScript

```
const { Prisma } = require('prisma-binding');

const db = new Prisma({
  typeDefs: 'src/generated/prisma.graphql',
  endpoint: process.env.PRISMA_ENDPOINT,
  secret: process.env.PRISMA_SECRET,
  debug: false,
});

module.exports = db;
```

- Create `/src/resolvers/Mutation.js`

```
const Mutations = {
  async createItem(parent, args, ctx, info) {
    const item = await ctx.db.mutation.createItem(
      { data: { ...args } }, info
    );

    return item;
  }
};

module.exports = Mutations;
```

- Create `/src/resolvers/Query.js`

```
const Query = {
  async items(parent, args, ctx, info) {
    const items = await ctx.db.query.items();
    return items;
  }
};

module.exports = Query;
```

    * If the query resolver is the exact same as the Prisma API query, you just forward it from Yoga to Prisma

```
const { forwardTo } = require('prisma-binding');

const Query = {
  items: forwardTo('db')
};

module.exports = Query;
```

- Create `/src/schema.graphql` to define types of the server
  - Used by Yoga
  - Client facing API
  - A “middleware” that the client calls to interact with the generated Prisma API

```
# import * from './generated/prisma.graphql'

type Mutation {
  createItem(
    title: String
    description: String
  ): Item!
}

type Query {
  items: [Item]!
}
```

- Create `/src/createServer.js` to define the Yoga server

```
const { GraphQLServer } = require('graphql-yoga');
const Mutation = require('./resolvers/Mutation');
const Query = require('./resolvers/Query');
const db = require('./db');

function createServer() {
  return new GraphQLServer({
    typeDefs: './src/schema.graphql',
    resolvers: {
      Mutation,
      Query,
    },
    resolverValidationOptions: {
      requireResolversForResolveType: false,
    },
    context: req => ({ ...req, db }),
  });
}

module.exports = createServer;
```

    * The ``typeDefs`` constant defines your GraphQL schema
    * The ``resolvers`` object is the actual implementation of the GraphQL schema
        * Mirrors the ``Query``, ``Mutation`` and ``Subscription`` types and their fields from your application schema
        * Each field in the application schema is represented by a function with the same name in that object
    * This tells the server what API operations are accepted and how they should be resolved
    * ``context`` is an object that gets passed through the resolver chain that every resolver can read from or write to

- Create `/src/index.js` to start Node server
  - Instantiates and starts the Yoga server

```
require('dotenv').config();
const createServer = require('./createServer');
const db = require('./db');

const server = createServer();

server.start(
  {
    cors: {
      credentials: true,
      origin: process.env.FRONTEND_URL
    }
  },
  deets => {
    console.log(`Server is now running on port http:/localhost:${deets.port}`);
  }
);
```

## Updating data Types in GraphQL

- Update data model for Prisma
  - `datamodel.prisma`
- Deploy to Prisma to generate an updated API
  - `prisma deploy` or `npm run deploy`
- Update typeDef schema for Yoga
  - Create queries/mutations and define the arguments and their types
- Create resolvers for each typeDef in the Yoga schema
  - Place all the custom logic applied to the data before passed to Prisma
  - The Prisma types are passed in as the third parameter (`ctx`)
    - access using `ctx.db.mutation.whateverType`
  - The arguments from the Yoga schema types are passed in as the second parameter (`args`)

---

# _Apollo Server_

- https://github.com/apollographql/apollo-server

## Data sources

- https://www.apollographql.com/docs/apollo-server/features/data-sources.html
- Data sources are classes that encapsulate fetching data from a particular service
- Built-in support for caching, deduplication, and error handling
- Calls made inside of a datasource class using `this.get|post|put` etc. are cached using a hardcoded namespace called `httpcache`
  - If you use `Redis` instead of the built in `LRU` cache, you can spin up your local `Redis` server and see the cache key entries for your self

### REST Data Source

- A `RESTDataSource` is responsible for fetching data from a given REST API
- `npm install apollo-datasource-rest --save`
- To define a data source, extend the `RESTDataSource` class and implement the data fetching methods that your resolvers require
- There are methods built-in to allow for `GET`, `POST`, `PUT`, `PATCH`, and `DELETE` requests
- Also accepts a third `options` parameter
  - Use to set things like headers and referrers

### Connect a REST API:

- Let’s connect the [Space-X v2 REST API](https://github.com/r-spacex/SpaceX-API) to our graph
- `npm install apollo-datasource-rest --save`
- Create our `LaunchAPI` data source

```
const { RESTDataSource } = require('apollo-datasource-rest');

class LaunchAPI extends RESTDataSource {
  constructor() {
    super();
    this.baseURL = 'https://api.spacexdata.com/v2/';
  }
}

module.exports = LaunchAPI;
```

- The next step is to add methods to the `LaunchAPI` data source that correspond to the queries our graph API needs to fetch

```
async getAllLaunches() {
  const response = await this.get('launches');
  return Array.isArray(response)
    ? response.map(launch => this.launchReducer(launch))
    : [];
}
```

- Write a `launchReducer` function to transform the data into that shape

```
launchReducer(launch) {
  return {
    id: launch.flight_number || 0,
    cursor: `${launch.launch_date_unix}`,
    site: launch.launch_site && launch.launch_site.site_name,
    mission: {
      name: launch.mission_name,
      missionPatchSmall: launch.links.mission_patch_small,
      missionPatchLarge: launch.links.mission_patch,
    },
    rocket: {
      id: launch.rocket.rocket_id,
      name: launch.rocket.rocket_name,
      type: launch.rocket.rocket_type,
    },
  };
}
```

### Build a custom data source

### Connect a database:

- Apollo doesn’t have support for a SQL data source yet
- We will need to create a custom data source for our database by extending the generic Apollo data source class
- You can create your own with the `apollo-datasource` package
- `npm install apollo-datasource-rest --save`
- Core concepts for creating your own data source:
  - The `initialize` method
    - You’ll need to implement this method if you want to pass in any configuration options to your class
  - `this.context`
    - A graph API’s context is an object that’s shared among every resolver in a GraphQL request
    - Useful for storing user information
  - Caching
    - While the REST data source comes with its own built in cache, the generic data source does not
    - You can use [our cache primitives](https://www.apollographql.com/docs/apollo-server/features/data-sources.html#Using-Memcached-Redis-as-a-cache-storage-backend) to build your own

```
const { DataSource } = require('apollo-datasource');
const isEmail = require('isemail');

class UserAPI extends DataSource {
  constructor({ store }) {
    super();
    this.store = store;
  }

  /**
   * This is a function that gets called by ApolloServer when being setup.
   * This function gets called with the datasource config including things
   * like caches and context. We'll assign this.context to the request context
   * here, so we can know about the user making requests
   */
  initialize(config) {
    this.context = config.context;
  }

  /**
   * User can be called with an argument that includes email, but it doesn't
   * have to be. If the user is already on the context, it will use that user
   * instead
   */
  async findOrCreateUser({ email: emailArg } = {}) {
    const email =
      this.context && this.context.user ? this.context.user.email : emailArg;
    if (!email || !isEmail.validate(email)) return null;

    const users = await this.store.users.findOrCreate({ where: { email } });
    return users && users[0] ? users[0] : null;
  }
}

module.exports = UserAPI;
```

### Add data sources to Apollo Server

- Create a `dataSources` property on your `ApolloServer` that corresponds to a function that returns an object with your instantiated data sources
- Import `createStore` where we defined our database
- Create our database by calling `createStore`
- Add the `dataSources` function to our `ApolloServer` to connect `LaunchAPI` and `UserAPI` to our graph
- Pass in our database we created to the `UserAPI` data source
- Apollo Server will put the data sources on the context for every request, so you can access them from your resolvers

```
const { createStore } = require('./utils');

const LaunchAPI = require('./datasources/launch');
const UserAPI = require('./datasources/user');

const store = createStore();

const server = new ApolloServer({
  typeDefs,
  dataSources: () => ({
    launchAPI: new LaunchAPI(),
    userAPI: new UserAPI({ store }),
  })
});
```

## Resolvers

###

Connecting resolvers to Apollo Server

- Connect our resolver map to Apollo Server. Right now, it’s just an empty object, but we should add it to our `ApolloServer` instance

```
const resolvers = require('./resolvers');

const server = new ApolloServer({
  typeDefs,
  resolvers,
  dataSources: () => ({
    launchAPI: new LaunchAPI(),
    userAPI: new UserAPI({ store }),
  })
});
```

### Write Query resolvers

- We destructure our data sources off the third argument, `context`, in order to call them in our resolvers

```
module.exports = {
  Query: {
    launches: async (_, __, { dataSources }) =>
      dataSources.launchAPI.getAllLaunches(),
    launch: (_, { id }, { dataSources }) =>
      dataSources.launchAPI.getLaunchById({ launchId: id }),
    me: async (_, __, { dataSources }) =>
      dataSources.userAPI.findOrCreateUser(),
  },
};
```

- Keep your resolvers thin as a best practice, which allows you to safely refactor without worrying about breaking your API

## Validation and Errors

- https://www.apollographql.com/docs/apollo-server/v2/features/errors.html
- https://blog.apollographql.com/graphql-validation-using-directives-4908fd5c1055
- GraphQL isn’t directly concerned about validation, but it operates between tech stacks that are:
  - the client application (e.g. showing validation messages)
  - the database (e.g. validation of entities before writing to the database)
- Apollo Server comes with a solution for global error handling:

```
const server = new ApolloServer({
  typeDefs,
  resolvers,
  formatError: error => {
    // remove the internal sequelize error message
    // leave only the important validation error
    const message = error.message
      .replace('SequelizeValidationError: ', '')
      .replace('Validation error: ', '');

    return {
      ...error,
      message
    };
  };
});
```

- If you want to add custom error handling to your resolver, you can add the commonly `try`/`catch` block statements for `async`/`await`

```
Mutation: {
      createMessage: async (parent, { text }, { me, models }) => {
        try {
          return await models.Message.create({
            text,
            userId: me.id
          });
        } catch (error) {
          throw Error(error);
        }
      }
    },
```

    * You could also use your custom message here with `throw Error('My error message.');`

## Paginated queries

- Pagination ensures that the server only sends data in small chunks
- Cursor-based pagination is our recommended approach over numbered pages
  - It eliminates the possibility of skipping items and displaying the same item more than once
- In cursor-based pagination, a constant pointer (or cursor) is used to keep track of where in the data set the next items should be fetched from
- In `src/schema.js`

```
type Query {
  launches(
    """
    The number of results to show. Must be >= 1. Default = 20
    """
    pageSize: Int
    """
    If you add a cursor here, it will only return results _after_ this cursor
    """
    after: String
  ): LaunchConnection!
  launch(id: ID!): Launch
  me: User
}

"""
Simple wrapper around our list of launches that contains a cursor to the
last item in the list. Pass this cursor to the launches query to fetch results
after these.
"""
type LaunchConnection {
  cursor: String!
  hasMore: Boolean!
  launches: [Launch]!
}
```

- We’ve added comments (docstrings) to our schema, indicated by `"""`
- The `launches` query takes in two parameters, `pageSize` and `after`, and returns a `LaunchConnection`
- The `LaunchConnection` type returns a result that shows the list of launches, in addition to:
  - A `cursor` field that keeps track of where we are in the list
  - A `hasMore` field to indicate if there’s more data to be fetched
- Update Query resolver for `launches`

```
const { paginateResults } = require('./utils');

module.exports = {
  Query: {
    launches: async (_, { pageSize = 20, after }, { dataSources }) => {
      const allLaunches = await dataSources.launchAPI.getAllLaunches();
      // we want these in reverse chronological order
      allLaunches.reverse();

      const launches = paginateResults({
        after,
        pageSize,
        results: allLaunches
      });

      return {
        launches,
        cursor: launches.length ? launches[launches.length - 1].cursor : null,
        // if the cursor of the end of the paginated results is the same as the
        // last item in _all_ results, then there are no more results after this
        hasMore: launches.length
          ? launches[launches.length - 1].cursor !==
            allLaunches[allLaunches.length - 1].cursor
          : false
      };
    }
  }
};
```

- `utils.js`

```
module.exports.paginateResults = ({
  after: cursor,
  pageSize = 20,
  results,
  // can pass in a function to calculate an item's cursor
  getCursor = () => null
}) => {
  if (pageSize < 1) return [];

  if (!cursor) return results.slice(0, pageSize);
  const cursorIndex = results.findIndex(item => {
    // if an item has a `cursor` on it, use that, otherwise try to generate one
    let itemCursor = item.cursor ? item.cursor : getCursor(item);

    // if there's still not a cursor, return false by default
    return itemCursor ? cursor === itemCursor : false;
  });

  return cursorIndex >= 0
    ? cursorIndex === results.length - 1 // don't let us overflow
      ? []
      : results.slice(
          cursorIndex + 1,
          Math.min(results.length, cursorIndex + 1 + pageSize)
        )
    : results.slice(0, pageSize);
};
```

## Authenticate users

- https://www.apollographql.com/docs/apollo-server/features/authentication.html
- Steps you’ll want to follow:

  1. The context function on your `ApolloServer` instance is called with the request object each time a GraphQL operation hits your API
     1. Use this request object to read the authorization headers
  2. Authenticate the user within the context function
  3. Once the user is authenticated, attach the user to the object returned from the context function
     1. This allows us to read the user’s information from within our data sources and resolvers, so we can authorize whether they can access the data

- In `src/index.js,` update the `context` function on `ApolloServer`

```
const isEmail = require('isemail');

const server = new ApolloServer({
  context: async ({ req }) => {
    // simple auth check on every request
    const auth = (req.headers && req.headers.authorization) || '';
    const email = Buffer.from(auth, 'base64').toString('ascii');

    // if the email isn't formatted validly, return null for user
    if (!isEmail.validate(email)) return { user: null };
    // find a user by their email
    const users = await store.users.findOrCreate({ where: { email } });
    const user = users && users[0] ? users[0] : null;

    return { user: { ...user.dataValues } };
  },
  // .... with the rest of the server object code below
  // .... typeDefs, resolvers, etc....
```

- Add mutation resolver
  - It receives an email address and returns a token if a user exists

```
Mutation: {
  login: async (_, { email }, { dataSources }) => {
    const user = await dataSources.userAPI.findOrCreateUser({ email });
    if (user) return Buffer.from(email).toString('base64');
  }
},
```

### JWT

- To create a JWT, we’ll use the popular jsonwebtoken node package
  - `npm install jsonwebtoken --save`

```
import { ApolloServer, AuthenticationError } from 'apollo-server-express';
import jwt from 'jsonwebtoken';
import 'dotenv/config';

const getMe = async req => {
  const token = req.headers['x-token'];

  if (token) {
    try {
      return await jwt.verify(token, process.env.JWT_SECRET);
    } catch (e) {
      throw new AuthenticationError('Your session expired. Sign in again.');
    }
  }
};

const server = new ApolloServer({
  typeDefs,
  resolvers,
  context: async ({ req }) => {
    const me = await getMe(req);

    return {
      models,
      me,
      secret: process.env.JWT_SECRET
    };
  }
});
```

- schema

```
extend type Mutation {
  signUp(username: String!, email: String!, password: String!): Token!
  signIn(login: String!, password: String!): Token!
}

type Token {
  token: String!
}
```

- token function

```
import jwt from 'jsonwebtoken';

const createToken = async (user, secret, expiresIn) => {
  const { id, email, username } = user;
  return await jwt.sign({ id, email, username }, secret, {
    expiresIn,
  });
};
```

- resolver

```
const {
  AuthenticationError,
  UserInputError
} = require('apollo-server-express');

Mutation: {
  signUp: async (
    parent,
    { username, email, password },
    { models, secret }
  ) => {
    const user = await models.User.create({
      username,
      email,
      password
    });

    return { token: createToken(user, secret, '30m') };
  },
  signIn: async (parent, { login, password }, { models, secret }) => {
    const user = await models.User.findByLogin(login);

    if (!user) {
      throw new UserInputError('No user found with this login credentials.');
    }

    const isValid = await user.validatePassword(password);

    if (!isValid) {
      throw new AuthenticationError('Invalid password.');
    }

    return { token: createToken(user, secret, '30m') };
  }
},
```

- Use add-ons like bcrypt to hash passwords
  - ` import`` ``bcrypt`` ``from`` ``'bcrypt'``; `
- The password is hashed with bcrypt before it gets stored every time a user is created in the database

```
// Using sequalize
User.beforeCreate(async user => {
  user.password = await user.generatePasswordHash();
});

User.prototype.generatePasswordHash = async function() {
  const saltRounds = 10;
  return await bcrypt.hash(this.password, saltRounds);
};

User.prototype.validatePassword = async function(password) {
  return await bcrypt.compare(password, this.password);
};
```

- Let’s implement the second mutation for the authentication mechanism: the `signIn` mutation

## Authenticate Resolvers

- Introduce an authorization abstraction layer for protecting GraphQL operations, with solutions called combined resolvers or resolver middleware
- `npm install graphql-resolvers --save`
- `/resolvers/authorization.js`

```
import { ForbiddenError } from 'apollo-server-express';
import { skip } from 'graphql-resolvers';

export const isAuthenticated = (parent, args, { me }) =>
  me ? skip : new ForbiddenError('Not authenticated as user.');
```

- `isAuthenticated()` resolver function acts as middleware, either continuing with the next resolver (skip), or performing another action, like returning an error
- Since it is a resolver function itself, it has the same arguments as a normal resolver
- A guarding resolver can be used when a message is created
- The new resolver is used to protect the resolvers by combining them

```
import { combineResolvers } from 'graphql-resolvers';
import { isAuthenticated } from './authorization';

Mutation: {
  createMessage: combineResolvers(
    isAuthenticated,
    async (parent, { text }, { models, me }) => {
      try {
        return await models.Message.create({
          text,
          userId: me.id
        });
      } catch (error) {
        throw new Error(error);
      }
    }
  )
};
```

- Now the `isAuthenticated()` resolver function always runs before the resolver that creates the message associated with the authenticated user in the database

## Permission-based Authorization

- Permissions require another protecting resolver that is more specific
- Add guarding resolver

```
export const isMessageOwner = async (parent, { id }, { models, me }) => {
  const message = await models.Message.findById(id, { raw: true });

  if (message.userId !== me.id) {
    throw new ForbiddenError('Not authenticated as owner.');
  }

  return skip;
};
```

- Update resolver

```
import { combineResolvers } from 'graphql-resolvers';
import { isAuthenticated, isMessageOwner } from './authorization';

Mutation: {
  deleteMessage: combineResolvers(
    isAuthenticated,
    isMessageOwner,
    async (parent, { id }, { models }) => {
      return await models.Message.destroy({ where: { id } });
    }
  )
};
```

## Role-based Authorization

- This allows you to create users with sets of permissions
- Add `role` field to the `User` type

```
type User {
  id: ID!
  username: String!
  email: String!
  role: String
  messages: [Message!]
}
```

- Add `role` to JWT

```
const createToken = async (user, secret, expiresIn) => {
  const { id, email, username, role } = user;
  return await jwt.sign({ id, email, username, role }, secret, {
    expiresIn,
  });
};
```

- Add guarding resolver

```
export const isAdmin = (parent, args, { me: { role } }) =>
  role === 'ADMIN' ? skip : new ForbiddenError('Not authorized as admin.');
```

- Update resolver

```
import { combineResolvers } from 'graphql-resolvers';
import { isAuthenticated, isAdmin } from './authorization';

Mutation: {
  deleteUser: combineResolvers(
    isAuthenticated,
    isAdmin,
    async (parent, { id }, { models }) => {
      return await models.User.destroy({
        where: { id },
      });
    },
  ),
};
```

- In a more elaborate role-based architecture, the role might change from a string to an array that contains many roles
  - It eliminates the need for an equal check, since you can check to see if the array includes a targeted role
  - Using arrays with a roles is the foundation for a sophisticated role-based authorization setup

## Error Handling

- https://blog.apollographql.com/full-stack-error-handling-with-graphql-apollo-5c12da407210
- `AuthenticationError` — for authentication failures
  - somebody really is who they claim to be
- `ForbiddenError` — for authorization failures
  - who is allowed to do what
- `UserInputError` — for validation errors on user input
- As a fallback for uncaught failures, any other unknown errors thrown within your resolver will add the code `INTERNAL_SERVER_ERROR`

* Apollo Client also distinguishes between two kinds of errors in the GraphQL response
  - `networkError`
    - Errors that are thrown outside of your resolvers
    - If networkError is present in your response, it means your entire query was rejected, and therefore no data was returned
    - For example, the client failed to connect to your GraphQL endpoint, or some error occurred within your request middleware, or there was an error in the parse/validation phase of your query
  - `graphQLErrors`
    - Any error that is thrown within your resolvers
    - Since we have multiple resolvers executing that are all potential sources of errors, we need an array to represent all of them
    - More importantly, `graphQLErrors` from failed resolvers can be returned alongside data/fields that resolved successfully

## Deployment

### Now v2

- `cd backend`
- `now.json`

```
{
  "name": "apollographql-fullstack",
  "version": 2,
  "builds": [{ "src": "src/index.js", "use": "@now/node-server" }],
  "routes": [{ "src": "/(.*)", "dest": "src/index.js" }]
}
```

- `now`

## Packages

- https://github.com/apollographql/apollo-server/tree/master/packages
- `apollo-datasource-rest`
  - `npm install apollo-datasource-rest —save`
  - This package exposes the `RESTDataSource` class that is responsible for fetching data from a REST API
  - To build a data source for a REST API, extend the `RESTDataSource` class and define `this.baseURL`
  - `RESTDataSource` also sets up an in-memory cache that caches responses from our REST resources with no additional setup
  - We call this partial query caching
  - What’s great about this cache is that you can reuse existing caching logic that your REST API exposes
  - The Apollo REST data sources has helper methods that correspond to HTTP verbs like `GET` and `POST`
  - Must transform our data into the shape our schema expects

---

# _Apollo Engine_

- https://www.apollographql.com/docs/platform/schema-registry.html
- Benefits of publishing a schema:
  - Powers developer tooling like VSCode and keep track of schema changes
  - Gives you the power to track and manage changes in the schema over time
  - Unlocks many features necessary for running a graph API in production
  - Powering editor tools like the [Apollo VS Code extension](https://marketplace.visualstudio.com/items?itemName=apollographql.vscode-apollo)
  - Empowering better code reviews and safer changes with [schema validation](https://www.apollographql.com/docs/platform/schema-validation.html)
  - Having a single point of knowledge for all teams to view through the [Apollo schema explorer](https://engine.apollographql.com/)
  - Sharing upcoming changes with [schema tags](https://www.apollographql.com/docs/platform/schema-registry.html#schema-tags)
  - Protecting the server along with the [Apollo operation registry](https://www.apollographql.com/docs/platform/operation-registry.html)
  - Having a historical view of how a schema changes with the [Apollo schema history tab in Engine](https://www.apollographql.com/docs/platform/schema-registry.html#history)
- Some features:
  - Schema explorer
    - With Engine’s powerful schema registry, you can quickly explore all the types and fields in your schema with usage statistics on each field
    - This metric makes you understand the cost of a field
      - How expensive is a field?
      - Is a certain field in so much demand?
  - Schema history
    - Apollo Engine’s schema history allows developers to confidently iterate a graph’s schema by validating the new schema against field-level usage data from the previous schema
    - This empowers developers to avoid breaking changes by providing insights into which clients will be broken by a new schema
  - Performance analytics
    - Fine-grained insights into every field, resolvers and operations of your graph’s execution
  - Performance alerts
    - You can configure notifications to be sent to various channels like Slack, and PagerDuty
    - Apollo Engine can be set to send alerts when a request rate, duration or error rate exceeds a certain threshold
- Just like npm is a registry for JavaScript packages, Apollo Engine contains a schema registry that makes it simple to pull the most recent schema from the cloud
- In a production application, you should set up this publishing script as part of your CI workflow

## Setup

- First, we need an Apollo Engine API key
- Navigate to [Apollo Engine](https://engine.apollographql.com/), login, and click on New Service at the top
- The prompt will instruct you to name your service
- When you’re finished, click Create Service
- You’ll see a key appear prefixed by `service:`
- Copy that key and save it as an environment variable
  - It’s important to make sure we don’t check our Engine API key into version control
- Create `.env` in the server root
  - `ENGINE_API_KEY=service:<your-service-name>:<hash-from-apollo-engine>`
- First, start your server in one terminal window by running `npm start`
- In another terminal window
  - `npx apollo service:push --endpoint=http://localhost:4000`

---

# _GraphQLGen_

- https://oss.prisma.io/graphqlgen/
- https://github.com/prisma/graphqlgen
- Generate & scaffold type-safe resolvers based on your GraphQL Schema in TypeScript, Flow & Reason

```
language: typescript
schema: ./src/schema.graphql
models:
  files:
    - ./prisma/generated/prisma-client/index.d.ts
output: ./src/generated/graphqlgen.ts
resolver-scaffolding:
  output: ./src/tmp/
  layout: file-per-type
```

---
